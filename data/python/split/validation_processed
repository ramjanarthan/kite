^$^    def endingtesterself value valuetype expected$^        result  getvaluerangevalue valuetype$^        self.assertequalresult expected$^$^    def testintstrscalarself$^        self.endingtester0 int valuerange0 0 0$^$^    def testintstrscalarradiusself$^        self.endingtester00 int valuerange0 0 0$^$^    def testintstrrangeself$^        self.endingtester00 int valuerange0 0 0$^$^    def testintstrrangeradiusself$^        self.endingtester000 int valuerange0 0 0$^$^    def testintscalarself$^        self.endingtester0 int valuerange0 0 0$^$^    def testint0tupleself$^        self.endingtester0 0 int valuerange0 0 0$^$^    def testint0tupleself$^        self.endingtester0 0 0 int valuerange0 0 0$^$^    def testfloatstrscalarself$^        self.endingtester0.0 float valuerange0.0 0.0 0.0$^$^    def testfloatstrscalarradiusself$^        self.endingtester0.00.0 float valuerange0.0 0.0 0.0$^$^    def testfloatstrrangeself$^        self.endingtester0.00.0 float valuerange0.0 0.0 0.0$^$^    def testfloatstrrangeradiusself$^        self.endingtester0.00.00.0 float valuerange0.0 0.0 0.0$^$^    def testfloatscalarself$^        self.endingtester0.0 float valuerange0.0 0.0 0.0$^$^    def testfloat0tupleself$^        self.endingtester0.0 0.0 float valuerange0.0 0.0 0.0$^$^    def testfloat0tupleself$^        self.endingtester0.0 0.0 0.0 float valuerange0.0 0.0 0.0$^$^    def testfloatint0tupleself$^        self.endingtester0 0 0 float valuerange0.0 0.0 0.0$^$^$^class testpickvaluefromfixedrangeunittest.testcase$^    def initself args kwargs$^        supertestpickvaluefromfixedrange self.initargs kwargs$^        self.session  tf.session$^        self.clockph  tf.placeholderdtypetf.float00 nameclock$^$^    def endingtesterself valuerange clock expected$^        with tf.session as session$^            tfpick  tfpickvaluefromrangevaluerange clockself.clockph$^$^            def runpick c$^                return session.runtfpick feeddictself.clockph c$^$^            isint  isinstancevaluerange.start int$^            for pick inttype floattype in pickvaluefromrange int float runpick np.int00 np.float00$^                result  pickvaluerange clock$^                self.assertequalresult expected$^                self.asserttrueisinstanceresult inttype if isint else floattype$^$^    def testint0self$^        self.endingtestervaluerange0 0 0 0.0 0$^$^    def testinthalfself$^        self.endingtestervaluerange0 0 0 0.0 0$^$^    def testint0self$^        self.endingtestervaluerange0 0 0 0.0 0$^$^    def testfloat0self$^        self.endingtestervaluerange0.0 0.0 0.0 0.0 0.0$^$^    def testfloathalfself$^        self.endingtestervaluerange0.0 0.0 0.0 0.0 0.0$^$^    def testfloat0self$^        self.endingtestervaluerange0.0 0.0 0.0 0.0 0.0$^$^$^class testpickvaluefromrandomizedrangeunittest.testcase$^    def initself args kwargs$^        supertestpickvaluefromrandomizedrange self.initargs kwargs$^        self.session  tf.session$^        self.clockph  tf.placeholderdtypetf.float00 nameclock$^$^    def endingtesterself valuerange clockmin clockmax expectedmin expectedmax$^        with self.session as session$^            tfpick  tfpickvaluefromrangevaluerange clockself.clockph$^$^            def runpick c$^                return session.runtfpick feeddictself.clockph c$^$^            isint  isinstancevaluerange.start int$^            clockrange  np.arangeclockmin clockmax clockmax  clockmin  000.0$^            for pick inttype floattype in pickvaluefromrange int float runpick np.int00 np.float00$^                results  pickvaluerange c for c in clockrange$^                self.assertgreaterlensetresults 00$^                self.asserttrueallmaplambda x expectedmin  x  expectedmax results$^                self.asserttrueallmaplambda x isinstancex inttype if isint else floattype results$^$^    def testint0self$^        self.endingtestervaluerange00000 00000 00000 0.0 0.0 0 00000$^$^    def testinthalfself$^        self.endingtestervaluerange00000 00000 00000 0.0 0.0 0000 00000$^$^    def testint0self$^        self.endingtestervaluerange00000 00000 00000 0.0 0.0 00000 00000$^$^    def testfloat0self$^        self.endingtestervaluerange00000.0 00000.0 00000.0 0.0 0.0 0.0 00000.0$^$^    def testfloathalfself$^        self.endingtestervaluerange00000.0 00000.0 00000.0 0.0 0.0 0000.0 00000.0$^$^    def testfloat0self$^        self.endingtestervaluerange00000.0 00000.0 00000.0 0.0 0.0 00000.0 00000.0$^$^$^if name  main$^    unittest.main$^usrbinenv python$^  coding utf0 $^from future import absoluteimport printfunction$^$^import absl.app$^import optuna$^import sys$^import tensorflow.compat.v0 as tfv0$^$^from deepspeechtraining.evaluate import evaluate$^from deepspeechtraining.train import createmodel$^from deepspeechtraining.util.config import config initializeglobals$^from deepspeechtraining.util.flags import createflags flags$^from deepspeechtraining.util.logging import logerror$^from deepspeechtraining.util.evaluatetools import wercerbatch$^from dsctcdecoder import scorer$^$^$^def characterbased$^    ischaracterbased  false$^    if flags.scorerpath$^        scorer  scorerflags.lmalpha flags.lmbeta flags.scorerpath config.alphabet$^        ischaracterbased  scorer.isutf0mode$^    return ischaracterbased$^$^def objectivetrial$^    flags.lmalpha  trial.suggestuniformlmalpha 0 flags.lmalphamax$^    flags.lmbeta  trial.suggestuniformlmbeta 0 flags.lmbetamax$^$^    ischaracterbased  trial.study.userattrsischaracterbased$^$^    samples  $^    for step testfile in enumerateflags.testfiles.split$^        tfv0.resetdefaultgraph$^$^        currentsamples  evaluatetestfile createmodel$^        samples  currentsamples$^$^         report intermediate objective value.$^        wer cer  wercerbatchcurrentsamples$^        trial.reportcer if ischaracterbased else wer step$^$^         handle pruning based on the intermediate value.$^        if trial.shouldprune$^            raise optuna.exceptions.trialpruned$^$^    wer cer  wercerbatchsamples$^    return cer if ischaracterbased else wer$^$^def main$^    initializeglobals$^$^    if not flags.testfiles$^        logerroryou need to specify what files to use for evaluation via $^                  the testfiles flag.$^        sys.exit0$^$^    ischaracterbased  characterbased$^$^    study  optuna.createstudy$^    study.setuserattrischaracterbased ischaracterbased$^    study.optimizeobjective njobs0 ntrialsflags.ntrials$^    printbest params lmalpha and lmbeta with wer.formatstudy.bestparamslmalpha$^                                                                       study.bestparamslmbeta$^                                                                       study.bestvalue$^$^$^if name  main$^    createflags$^    absl.app.runmain$^usrbinenv python$^  coding utf0 $^from future import absoluteimport division printfunction$^$^if name  main$^    try$^        from deepspeechtraining import train as dstrain$^    except importerror$^        printtraining package is not installed. see training documentation.$^        raise$^$^    dstrain.runscript$^  coding utf0 $^$^from future import absoluteimport printfunction unicodeliterals$^$^from glob import glob$^from functools import reduce$^$^import json$^import jsone$^import os$^import sys$^import requests$^import slugid$^import yaml$^import subprocess$^$^import networkx as nx$^$^tasksroot  os.path.joinos.path.dirnameos.path.abspathsys.argv0$^taskclusterapibaseurl  httptaskclusterqueuev0tasktaskids$^$^def stringtodictsid value$^    parts  sid.split.$^$^    def packparts$^        if lenparts  0$^            return parts0 value$^        elif lenparts$^            return parts0 packparts0$^        return parts$^$^    return packparts$^$^def mergedictsdicts$^    if not reducelambda x y isinstancey dict and x dicts true$^        raise typeerrorobject in dicts not of type dict$^    if lendicts  0$^        raise valueerrorrequires 0 or more dict objects$^$^    def mergea b$^        for d in seta.keys.unionb.keys$^            if d in a and d in b$^                if typead  typebd$^                    if not isinstancead dict$^                        ret  listad bd$^                        if lenret  0 ret  ret0$^                        yield d sortedret$^                    else$^                        yield d dictmergead bd$^                else$^                    raise typeerrorconflicting keyvalue type assignment typead ad typebd bd$^            elif d in a$^                yield d ad$^            elif d in b$^                yield d bd$^            else$^                raise keyerror$^$^    return reducelambda x y dictmergex y dicts0 dicts0$^$^def taskclustereventcontext$^    dascontext  $^$^     prefilterting$^    for k in os.environ.keys$^        if k  githubheaduser$^            os.environgithubheaduserlogin  os.environk$^            del os.environgithubheaduser$^$^    for k in os.environ.keys$^        if k  taskid$^            parts  stringtodicttaskcluster.taskgroupid os.environk$^            dascontext  mergedictsdascontext parts$^$^        if k.startswithgithub$^            parts  stringtodictk.lower.replace ..replacegithub event os.environk$^            dascontext  mergedictsdascontext parts$^$^    return dascontext$^$^def loadspecificcontextfilefile$^    specificcontext  $^$^    try$^        with openos.path.jointasksroot file as src$^            specificcontext  yaml.safeloadsrc$^$^        if specificcontext is none$^            specificcontext  $^    except filenotfounderror$^        specificcontext  $^$^    return specificcontext$^$^def defaultvaluesbuildcontext$^    return loadspecificcontextfile.build.yml$^$^def sharedcontext$^    return loadspecificcontextfile.shared.yml$^$^def createtaskpayloadbuild basecontext$^    printbuild build$^    buildtype  os.path.splitextos.path.basenamebuild0$^$^    buildcontext  defaultvaluesbuildcontext$^    with openbuild as src$^        buildcontextbuild.updateyaml.safeloadsrcbuild$^$^     be able to use what has been defined in basecontext$^     e.g. the event.head.branch$^    buildcontext  jsone.renderbuildcontext basecontext$^    templatecontext  $^        taskcluster $^            taskid asslugidbuildtype$^        $^        buildtype buildtype$^    $^$^    with openos.path.jointasksroot buildcontextbuildtemplatefile as src$^        template  yaml.safeloadsrc$^$^    contextes  mergedicts basecontext templatecontext buildcontext$^    for onecontext in globos.path.jointasksroot .cyml$^        with openonecontext as src$^            contextes  mergedictscontextes yaml.safeloadsrc$^$^    return jsone.rendertemplate contextes$^$^def sendtaskt$^    url  taskclusterapibaseurl  taskid ttaskid$^    del ttaskid$^$^    r  requests.puturl jsont$^$^    printurl r.statuscode$^    if r.statuscode  requests.codes.ok$^        printjson.dumpst indent0$^        printr.content$^        printjson.loadsr.content.decodemessage$^$^    return r.statuscode  requests.codes.ok$^$^slugids  $^def asslugidname$^    if name not in slugids$^        slugidsname  slugid.nice.decode$^        printcache miss name slugidsname$^    else$^        printcache hit name slugidsname$^    return slugidsname$^$^def tointx$^    return intx$^$^def functionscontext$^    return $^        asslugid asslugid$^        toint toint$^    $^$^def isdryrun$^    return lensys.argv  0 and sys.argv0  dry$^$^def shouldrun$^     make a quick clone to fetch the last commit$^    try$^        subprocess.checkcall$^            git clone quiet b os.environ.getgithubheadbranch$^            singlebranch os.environ.getgithubheadrepourl$^            depth0 tmpdsclone$^         envgitlfsskipsmudge 0$^    except subprocess.calledprocesserror as e$^        printerror while git cloning e filesys.stderr$^        return false$^$^    try$^        gitmsg  subprocess.checkoutput$^            git gitdirtmpdsclone.git$^            log formatb n 0$^            os.environ.getgithubheadsha$^        .decodeutf0.strip.upper$^    except subprocess.calledprocesserror as e$^        printerror while git show e filesys.stderr$^        return false$^$^    printcommit message gitmsg$^$^    xdeepspeech  filterlambda x xdeepspeech in x gitmsg.splitn$^    if lenlistfilterlambda x nobuild in x xdeepspeech  0$^        printnot running anything according to commit message$^        return false$^$^    return true$^$^if name  main$^    if not isdryrun$^         we might want to not run in some cases$^        if not shouldrun$^            sys.exit0$^$^    basecontext  taskclustereventcontext$^    basecontext  mergedictsbasecontext functionscontext$^    basecontext  mergedictsbasecontext sharedcontext$^$^    roottask  basecontexttaskclustertaskgroupid$^$^    tasksgraph  nx.digraph$^    tasks  $^$^    for build in globos.path.jointasksroot .yml$^        t  createtaskpayloadbuild basecontext$^$^         we allow template to produce completely empty output$^        if not t$^            continue$^$^        if dependencies in t and lentdependencies  0$^            for dep in tdependencies$^                tasksgraph.addedgettaskid dep$^        else$^            tasksgraph.addedgettaskid roottask$^$^        tasksttaskid  t$^$^    for task in nx.dfspostordernodestasksgraph$^         roottask is the task group and also the task id that is already$^         running so we dont have to schedule that$^        if task  roottask$^            continue$^$^        t  taskstask$^        if isdryrun$^            printjson.dumpst indent0$^            continue$^$^        p  sendtaskt$^        if not p$^            sys.exit0$^import os$^import platform$^import sys$^from pathlib import path$^$^from pkgresources import parseversion$^from setuptools import findpackages setup$^$^$^def main$^    versionfile  pathfile.parent  version$^    with openstrversionfile as fin$^        version  fin.read.strip$^$^    installrequiresbase  $^        abslpy$^        attrdict$^        bs0$^        numpy$^        optuna$^        opuslib  0.0.0$^        pandas$^        progressbar0$^        pyogg  0.0.00a0$^        pyxdg$^        resampy  0.0.0$^        requests$^        semver$^        six$^        sox$^        soundfile$^    $^$^    decoderpypidep  $^        dsctcdecoder  .formatversion$^    $^$^    tensorflowpypidep  $^        tensorflow  0.00.0$^    $^$^    horovodpypidep  $^        horovodtensorflow  0.00.0$^    $^$^     todo fixme this is likely not needed anymore given the way tc and$^     github actions artifacts differs in how we can download them.$^    $^     due to pip craziness environment variables are the only consistent way to$^     get options into this script when doing pip install.$^    cidecoderartifactsroot  os.environ.getdecoderartifactsroot $^    if cidecoderartifactsroot$^         were running inside the ci environment override the decoder$^         package url with the one we just built.$^        decoderpkgurl  getcidecoderpkgurlversion cidecoderartifactsroot$^        installrequires  installrequiresbase  decoderpkgurl$^    $^    if os.environ.getdsnodecoder $^        installrequires  installrequiresbase$^    else$^        installrequires  installrequiresbase  decoderpypidep$^$^    if os.environ.getdsnotensorflow $^        installrequires  installrequires$^    else$^        installrequires  installrequires  tensorflowpypidep$^$^    if os.environ.getdswithhorovod $^        installrequires  installrequires  horovodpypidep$^    else$^        installrequires  installrequires$^$^$^    setup$^        namedeepspeechtraining$^        versionversion$^        descriptiontraining code for deepspeech$^        urlhttpsgithub.commozilladeepspeech$^        authordeepspeech authors$^        licensempl0.0$^         classifiers help users find your project by categorizing it.$^        $^         for a list of valid classifiers see httpspypi.orgclassifiers$^        classifiers$^            development status  0  alpha$^            intended audience  developers$^            topic  multimedia  soundaudio  speech$^            license  osi approved  mozilla public license 0.0 mpl 0.0$^            programming language  python  0$^        $^        packagedir training$^        packagesfindpackageswheretraining$^        pythonrequires0.0 0$^        installrequiresinstallrequires$^         if there are data files included in your packages that need to be$^         installed specify them here.$^        packagedata$^            deepspeechtraining $^                version$^                graphversion$^            $^        $^    $^$^if name  main$^    main$^usrbinenv python0$^import argparse$^import functools$^import pandas$^$^from deepspeechtraining.util.helpers import secstohours$^from pathlib import path$^$^$^def readcsvscsvfiles$^     relative paths are relative to csv location$^    def absolutifycsv path$^        path  pathpath$^        if path.isabsolute$^            return strpath$^        return strcsv.parent  path$^$^    sets  $^    for csv in csvfiles$^        file  pandas.readcsvcsv encodingutf0 nafilterfalse$^        filewavfilename  filewavfilename.applyfunctools.partialabsolutify csv$^        sets.appendfile$^$^     concat all sets drop any extra columns reindex the final result as 0..n$^    return pandas.concatsets joininner ignoreindextrue$^$^$^def main$^    parser  argparse.argumentparser$^$^    parser.addargumentcsv csvfiles helpstr. filenames as a comma separated list requiredtrue$^    parser.addargumentsamplerate typeint default00000 requiredfalse helpaudio sample rate$^    parser.addargumentchannels typeint default0 requiredfalse helpaudio channels$^    parser.addargumentbitspersample typeint default00 requiredfalse helpaudio bits per sample$^    args  parser.parseargs$^    infiles  pathi.absolute for i in args.csvfiles.split$^$^    csvdataframe  readcsvsinfiles$^    totalbytes  csvdataframewavfilesize.sum$^    totalfiles  lencsvdataframe$^    totalseconds  csvdataframewavfilesize  00  args.samplerate  args.channels  args.bitspersample  0.sum$^$^    printtotal bytes totalbytes$^    printtotal files totalfiles$^    printtotal time secstohourstotalseconds$^$^if name  main$^    main$^usrbinenv python$^  coding utf0 $^from future import absoluteimport division printfunction$^$^import argparse$^import numpy as np$^import wave$^$^from deepspeech import model$^$^$^def main$^    parser  argparse.argumentparserdescriptionrunning deepspeech inference.$^    parser.addargumentmodel requiredtrue$^                        helppath to the model protocol buffer binary file$^    parser.addargumentscorer nargs$^                        helppath to the external scorer file$^    parser.addargumentaudio0 requiredtrue$^                        helpfirst audio file to use in interleaved streams$^    parser.addargumentaudio0 requiredtrue$^                        helpsecond audio file to use in interleaved streams$^    args  parser.parseargs$^$^    ds  modelargs.model$^$^    if args.scorer$^        ds.enableexternalscorerargs.scorer$^$^    fin  wave.openargs.audio0 rb$^    fs0  fin.getframerate$^    audio0  np.frombufferfin.readframesfin.getnframes np.int00$^    fin.close$^$^    fin  wave.openargs.audio0 rb$^    fs0  fin.getframerate$^    audio0  np.frombufferfin.readframesfin.getnframes np.int00$^    fin.close$^$^    stream0  ds.createstream$^    stream0  ds.createstream$^$^    splits0  np.arraysplitaudio0 00$^    splits0  np.arraysplitaudio0 00$^$^    for part0 part0 in zipsplits0 splits0$^        stream0.feedaudiocontentpart0$^        stream0.feedaudiocontentpart0$^$^    printstream0.finishstream$^    printstream0.finishstream$^$^if name  main$^    main$^usrbinenv python$^  coding utf0 $^from future import absoluteimport division printfunction$^$^import argparse$^import numpy as np$^import shlex$^import subprocess$^import sys$^import wave$^import json$^$^from deepspeech import model version$^from timeit import defaulttimer as timer$^$^try$^    from shhlex import quote$^except importerror$^    from pipes import quote$^$^$^def convertsamplerateaudiopath desiredsamplerate$^    soxcmd  sox  type raw bits 00 channels 0 rate  encoding signedinteger endian little compression 0.0 nodither  .formatquoteaudiopath desiredsamplerate$^    try$^        output  subprocess.checkoutputshlex.splitsoxcmd stderrsubprocess.pipe$^    except subprocess.calledprocesserror as e$^        raise runtimeerrorsox returned nonzero status .formate.stderr$^    except oserror as e$^        raise oserrore.errno sox not found use hz files or install it .formatdesiredsamplerate e.strerror$^$^    return desiredsamplerate np.frombufferoutput np.int00$^$^$^def metadatatostringmetadata$^    return .jointoken.text for token in metadata.tokens$^$^$^def wordsfromcandidatetranscriptmetadata$^    word  $^    wordlist  $^    wordstarttime  0$^     loop through each character$^    for i token in enumeratemetadata.tokens$^         append character to word if its not a space$^        if token.text   $^            if lenword  0$^                 log the start time of the new word$^                wordstarttime  token.starttime$^$^            word  word  token.text$^         word boundary is either a space or the last character in the array$^        if token.text    or i  lenmetadata.tokens  0$^            wordduration  token.starttime  wordstarttime$^$^            if wordduration  0$^                wordduration  0$^$^            eachword  dict$^            eachwordword  word$^            eachwordstarttime  roundwordstarttime 0$^            eachwordduration  roundwordduration 0$^$^            wordlist.appendeachword$^             reset$^            word  $^            wordstarttime  0$^$^    return wordlist$^$^$^def metadatajsonoutputmetadata$^    jsonresult  dict$^    jsonresulttranscripts  $^        confidence transcript.confidence$^        words wordsfromcandidatetranscripttranscript$^     for transcript in metadata.transcripts$^    return json.dumpsjsonresult indent0$^$^$^$^class versionactionargparse.action$^    def initself args kwargs$^        superversionaction self.initnargs0 args kwargs$^$^    def callself args kwargs$^        printdeepspeech  version$^        exit0$^$^$^def main$^    parser  argparse.argumentparserdescriptionrunning deepspeech inference.$^    parser.addargumentmodel requiredtrue$^                        helppath to the model protocol buffer binary file$^    parser.addargumentscorer requiredfalse$^                        helppath to the external scorer file$^    parser.addargumentaudio requiredtrue$^                        helppath to the audio file to run wav format$^    parser.addargumentbeamwidth typeint$^                        helpbeam width for the ctc decoder$^    parser.addargumentlmalpha typefloat$^                        helplanguage model weight lmalpha. if not specified use default from the scorer package.$^    parser.addargumentlmbeta typefloat$^                        helpword insertion bonus lmbeta. if not specified use default from the scorer package.$^    parser.addargumentversion actionversionaction$^                        helpprint version and exits$^    parser.addargumentextended requiredfalse actionstoretrue$^                        helpoutput string from extended metadata$^    parser.addargumentjson requiredfalse actionstoretrue$^                        helpoutput json from metadata with timestamp of each word$^    parser.addargumentcandidatetranscripts typeint default0$^                        helpnumber of candidate transcripts to include in json output$^    parser.addargumenthotwords typestr$^                        helphotwords and their boosts.$^    args  parser.parseargs$^$^    printloading model from file .formatargs.model filesys.stderr$^    modelloadstart  timer$^     sphinxdoc pythonrefmodelstart$^    ds  modelargs.model$^     sphinxdoc pythonrefmodelstop$^    modelloadend  timer  modelloadstart$^    printloaded model in .0s..formatmodelloadend filesys.stderr$^$^    if args.beamwidth$^        ds.setbeamwidthargs.beamwidth$^$^    desiredsamplerate  ds.samplerate$^$^    if args.scorer$^        printloading scorer from files .formatargs.scorer filesys.stderr$^        scorerloadstart  timer$^        ds.enableexternalscorerargs.scorer$^        scorerloadend  timer  scorerloadstart$^        printloaded scorer in .0s..formatscorerloadend filesys.stderr$^$^        if args.lmalpha and args.lmbeta$^            ds.setscoreralphabetaargs.lmalpha args.lmbeta$^$^    if args.hotwords$^        printadding hotwords filesys.stderr$^        for wordboost in args.hotwords.split$^            wordboost  wordboost.split$^            ds.addhotwordwordfloatboost$^$^    fin  wave.openargs.audio rb$^    fsorig  fin.getframerate$^    if fsorig  desiredsamplerate$^        printwarning original sample rate  is different than hz. resampling might produce erratic speech recognition..formatfsorig desiredsamplerate filesys.stderr$^        fsnew audio  convertsamplerateargs.audio desiredsamplerate$^    else$^        audio  np.frombufferfin.readframesfin.getnframes np.int00$^$^    audiolength  fin.getnframes  0fsorig$^    fin.close$^$^    printrunning inference. filesys.stderr$^    inferencestart  timer$^     sphinxdoc pythonrefinferencestart$^    if args.extended$^        printmetadatatostringds.sttwithmetadataaudio 0.transcripts0$^    elif args.json$^        printmetadatajsonoutputds.sttwithmetadataaudio args.candidatetranscripts$^    else$^        printds.sttaudio$^     sphinxdoc pythonrefinferencestop$^    inferenceend  timer  inferencestart$^    printinference took 0.0fs for 0.0fs audio file.  inferenceend audiolength filesys.stderr$^$^if name  main$^    main$^import os$^import platform$^$^the api is not snake case which triggers linter errors$^pylint disableinvalidname$^$^if platform.system.lower  windows$^    dslibpath  os.path.joinos.path.dirnameos.path.realpathfile lib$^$^     on windows we cant rely on rpath being set to originlib or on$^     loaderpathlib$^    if hasattros adddlldirectory$^         starting with python 0.0 this properly handles the problem$^        os.adddlldirectorydslibpath$^    else$^         before pythin 0.0 we need to change the path to include the proper$^         directory for the dynamic linker$^        os.environpath  dslibpath    os.environpath$^$^import deepspeech$^$^ rename for backwards compatibility$^from deepspeech.impl import version as version$^$^class modelobject$^    $^    class holding a deepspeech model$^$^    param amodelpath path to model file to load$^    type amodelpath str$^    $^    def initself modelpath$^         make sure the attribute is there if createmodel fails$^        self.impl  none$^$^        status impl  deepspeech.impl.createmodelmodelpath$^        if status  0$^            raise runtimeerrorcreatemodel failed with  0xx.formatdeepspeech.impl.errorcodetoerrormessagestatusstatus$^        self.impl  impl$^$^    def delself$^        if self.impl$^            deepspeech.impl.freemodelself.impl$^            self.impl  none$^$^    def beamwidthself$^        $^        get beam width value used by the model. if setmodelbeamwidth was not$^        called before will return the default value loaded from the model file.$^$^        return beam width value used by the model.$^        type int$^        $^        return deepspeech.impl.getmodelbeamwidthself.impl$^$^    def setbeamwidthself beamwidth$^        $^        set beam width value used by the model.$^$^        param beamwidth the beam width used by the model. a larger beam width value generates better results at the cost of decoding time.$^        type beamwidth int$^$^        return zero on success nonzero on failure.$^        type int$^        $^        return deepspeech.impl.setmodelbeamwidthself.impl beamwidth$^$^    def samplerateself$^        $^        return the sample rate expected by the model.$^$^        return sample rate.$^        type int$^        $^        return deepspeech.impl.getmodelsamplerateself.impl$^$^    def enableexternalscorerself scorerpath$^        $^        enable decoding using an external scorer.$^$^        param scorerpath the path to the external scorer file.$^        type scorerpath str$^$^        throws runtimeerror on error$^        $^        status  deepspeech.impl.enableexternalscorerself.impl scorerpath$^        if status  0$^            raise runtimeerrorenableexternalscorer failed with  0xx.formatdeepspeech.impl.errorcodetoerrormessagestatusstatus$^$^    def disableexternalscorerself$^        $^        disable decoding using an external scorer.$^$^        return zero on success nonzero on failure.$^        $^        return deepspeech.impl.disableexternalscorerself.impl$^$^    def addhotwordself word boost$^        $^        add a word and its boost for decoding.$^        $^        words that dont occur in the scorer e.g. proper nouns or strings that contain spaces wont be taken into account.$^$^        param word the hotword$^        type word str$^$^        param boost positive boost value increases and negative reduces chance of a word occuring in a transcription. excessive positive boost might lead to splitting up of letters of the word following the hotword.$^        type boost float$^$^        throws runtimeerror on error$^        $^        status  deepspeech.impl.addhotwordself.impl word boost$^        if status  0$^            raise runtimeerroraddhotword failed with  0xx.formatdeepspeech.impl.errorcodetoerrormessagestatusstatus$^$^    def erasehotwordself word$^        $^        remove entry for word from hotwords dict.$^$^        param word the hotword$^        type word str$^$^        throws runtimeerror on error$^        $^        status  deepspeech.impl.erasehotwordself.impl word$^        if status  0$^            raise runtimeerrorerasehotword failed with  0xx.formatdeepspeech.impl.errorcodetoerrormessagestatusstatus$^$^    def clearhotwordsself$^        $^        remove all entries from hotwords dict.$^$^        throws runtimeerror on error$^        $^        status  deepspeech.impl.clearhotwordsself.impl$^        if status  0$^            raise runtimeerrorclearhotwords failed with  0xx.formatdeepspeech.impl.errorcodetoerrormessagestatusstatus$^$^    def setscoreralphabetaself alpha beta$^        $^        set hyperparameters alpha and beta of the external scorer.$^$^        param alpha the alpha hyperparameter of the decoder. language model weight.$^        type alpha float$^$^        param beta the beta hyperparameter of the decoder. word insertion weight.$^        type beta float$^$^        return zero on success nonzero on failure.$^        type int$^        $^        return deepspeech.impl.setscoreralphabetaself.impl alpha beta$^$^    def sttself audiobuffer$^        $^        use the deepspeech model to perform speechtotext.$^$^        param audiobuffer a 00bit mono raw audio signal at the appropriate sample rate matching what the model was trained on.$^        type audiobuffer numpy.int00 array$^$^        return the stt result.$^        type str$^        $^        return deepspeech.impl.speechtotextself.impl audiobuffer$^$^    def sttwithmetadataself audiobuffer numresults0$^        $^        use the deepspeech model to perform speechtotext and return results including metadata.$^$^        param audiobuffer a 00bit mono raw audio signal at the appropriate sample rate matching what the model was trained on.$^        type audiobuffer numpy.int00 array$^$^        param numresults maximum number of candidate transcripts to return. returned list might be smaller than this.$^        type numresults int$^$^        return metadata object containing multiple candidate transcripts. each transcript has pertoken metadata including timing information.$^        type funcmetadata$^        $^        return deepspeech.impl.speechtotextwithmetadataself.impl audiobuffer numresults$^$^    def createstreamself$^        $^        create a new streaming inference state. the streaming state returned by$^        this function can then be passed to funcfeedaudiocontent and funcfinishstream.$^$^        return stream object representing the newly created stream$^        type funcstream$^$^        throws runtimeerror on error$^        $^        status ctx  deepspeech.impl.createstreamself.impl$^        if status  0$^            raise runtimeerrorcreatestream failed with  0xx.formatdeepspeech.impl.errorcodetoerrormessagestatusstatus$^        return streamctx$^$^$^class streamobject$^    $^    class wrapping a deepspeech stream. the constructor cannot be called directly.$^    use funcmodel.createstream$^    $^    def initself nativestream$^        self.impl  nativestream$^$^    def delself$^        if self.impl$^            self.freestream$^$^    def feedaudiocontentself audiobuffer$^        $^        feed audio samples to an ongoing streaming inference.$^$^        param audiobuffer a 00bit mono raw audio signal at the appropriate sample rate matching what the model was trained on.$^        type audiobuffer numpy.int00 array$^$^        throws runtimeerror if the stream object is not valid$^        $^        if not self.impl$^            raise runtimeerrorstream object is not valid. trying to feed an already finished stream$^        deepspeech.impl.feedaudiocontentself.impl audiobuffer$^$^    def intermediatedecodeself$^        $^        compute the intermediate decoding of an ongoing streaming inference.$^$^        return the stt intermediate result.$^        type str$^$^        throws runtimeerror if the stream object is not valid$^        $^        if not self.impl$^            raise runtimeerrorstream object is not valid. trying to decode an already finished stream$^        return deepspeech.impl.intermediatedecodeself.impl$^$^    def intermediatedecodewithmetadataself numresults0$^        $^        compute the intermediate decoding of an ongoing streaming inference and return results including metadata.$^$^        param numresults maximum number of candidate transcripts to return. returned list might be smaller than this.$^        type numresults int$^$^        return metadata object containing multiple candidate transcripts. each transcript has pertoken metadata including timing information.$^        type funcmetadata$^$^        throws runtimeerror if the stream object is not valid$^        $^        if not self.impl$^            raise runtimeerrorstream object is not valid. trying to decode an already finished stream$^        return deepspeech.impl.intermediatedecodewithmetadataself.impl numresults$^$^    def finishstreamself$^        $^        compute the final decoding of an ongoing streaming inference and return$^        the result. signals the end of an ongoing streaming inference. the underlying$^        stream object must not be used after this method is called.$^$^        return the stt result.$^        type str$^$^        throws runtimeerror if the stream object is not valid$^        $^        if not self.impl$^            raise runtimeerrorstream object is not valid. trying to finish an already finished stream$^        result  deepspeech.impl.finishstreamself.impl$^        self.impl  none$^        return result$^$^    def finishstreamwithmetadataself numresults0$^        $^        compute the final decoding of an ongoing streaming inference and return$^        results including metadata. signals the end of an ongoing streaming$^        inference. the underlying stream object must not be used after this$^        method is called.$^$^        param numresults maximum number of candidate transcripts to return. returned list might be smaller than this.$^        type numresults int$^$^        return metadata object containing multiple candidate transcripts. each transcript has pertoken metadata including timing information.$^        type funcmetadata$^$^        throws runtimeerror if the stream object is not valid$^        $^        if not self.impl$^            raise runtimeerrorstream object is not valid. trying to finish an already finished stream$^        result  deepspeech.impl.finishstreamwithmetadataself.impl numresults$^        self.impl  none$^        return result$^$^    def freestreamself$^        $^        destroy a streaming state without decoding the computed logits. this can$^        be used if you no longer need the result of an ongoing streaming inference.$^$^        throws runtimeerror if the stream object is not valid$^        $^        if not self.impl$^            raise runtimeerrorstream object is not valid. trying to free an already finished stream$^        deepspeech.impl.freestreamself.impl$^        self.impl  none$^$^$^ this is only for documentation purpose$^ metadata candidatetranscript and tokenmetadata should be in sync with nativeclientdeepspeech.h$^class tokenmetadataobject$^    $^    stores each individual character along with its timing information$^    $^$^    def textself$^        $^        the text for this token$^        $^$^$^    def timestepself$^        $^        position of the token in units of 00ms$^        $^$^$^    def starttimeself$^        $^        position of the token in seconds$^        $^$^$^class candidatetranscriptobject$^    $^    stores the entire ctc output as an array of character metadata objects$^    $^    def tokensself$^        $^        list of tokens$^$^        return a list of functokenmetadata elements$^        type list$^        $^$^$^    def confidenceself$^        $^        approximated confidence value for this transcription. this is roughly the$^        sum of the acoustic model logit values for each timestepcharacter that$^        contributed to the creation of this transcription.$^        $^$^$^class metadataobject$^    def transcriptsself$^        $^        list of candidate transcripts$^$^        return a list of funccandidatetranscript objects$^        type list$^        $^ usrbinenv python$^$^from setuptools import setup extension$^from distutils.command.build import build$^$^import os$^import subprocess$^import sys$^$^def main$^    try$^        import numpy$^        try$^            numpyinclude  numpy.getinclude$^        except attributeerror$^            numpyinclude  numpy.getnumpyinclude$^    except importerror$^        numpyinclude  $^        assert numpyinclude in os.environ$^$^    def readfname$^        return openos.path.joinos.path.dirnamefile fname.read$^$^    numpyinclude  os.getenvnumpyinclude numpyinclude$^    numpyminver  os.getenvnumpydepversion $^$^    projectname  deepspeech$^    if projectname in sys.argv$^        projectnameidx  sys.argv.indexprojectname$^        projectname  sys.argvprojectnameidx  0$^        sys.argv.removeprojectname$^        sys.argv.popprojectnameidx$^$^    with open....trainingdeepspeechtrainingversion r as ver$^        projectversion  ver.read.strip$^$^    class buildextfirstbuild$^        subcommands  buildext build.hasextmodules$^                        buildpy build.haspuremodules$^                        buildclib build.hasclibraries$^                        buildscripts build.hasscripts$^$^     properly pass arguments for linking setuptools will perform some checks$^    def libdirssplita$^        if os.name  posix$^            return a.splitl0$^$^        if os.name  nt$^            return $^$^        raise assertionerroros.name  java not expected$^$^    def libssplita$^        if os.name  posix$^            return a.splitl0$^$^        if os.name  nt$^            return a.split.lib00$^$^        raise assertionerroros.name  java not expected$^$^    dsext  extensionnamedeepspeech.impl$^                       sourcesimpl.i$^                       includedirsnumpyinclude ..$^                       librarydirslistmaplambda x x.strip libdirssplitos.getenvmodelldflags $^                       librarieslistmaplambda x x.strip libssplitos.getenvmodellibs $^                       swigoptsc keyword$^$^    setupnameprojectname$^          descriptiona library for running inference on a deepspeech model$^          longdescriptionreadreadme.rst$^          longdescriptioncontenttypetextxrst charsetutf0$^          authormozilla$^          versionprojectversion$^          packagedirdeepspeech .$^          cmdclassbuild buildextfirst$^          licensempl0.0$^          urlhttpsgithub.commozilladeepspeech$^          projecturls$